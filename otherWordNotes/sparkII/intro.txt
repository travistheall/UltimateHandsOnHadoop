Lesson One: Introduction
This course was developed in collaboration
with MetiStream and IBM analytics. This lesson is just a quick primer on data
notebooks to get you ready for the lab exercises. After completing this lesson, you should be
use zeppelin in your projects and identify the various notebooks you can use with Spark.
Apache Zeppelin is an interactive data analytics tool started by NFLabs. With Zeppelin you
can run code and create visualizations through a web interface. You can plug in virtually
any programming language or data processing backend.
Zeppelin comes configured with Scala and Spark, as well as markdown, Spark SQL, and shell.
You can visit the project homepage for more information.
Jupyter is an evolution of IPython, a mature python-based notebook. IPython is still the
Python kernel, but Jupyter also supports other languages including, Julia, Ruby, R, and Haskell.
It supports pyspark, the spark api for python, and visualizations using the pyplot library.
Visit jupyter.org for more information. The data scientist workbench is an interactive
data platform in development from IBM. It's build around Jupyter/Ipython notebooks. The
workbench comes pre-installed with Python, Scala, and R. You can collaborate, search
and share notebooks. There are many tutorials and notebooks available,
ranging from introductory to using advanced libraries. You can register to preview the
technology at datascientistworkbench.com Another option is Spark notebook, a fork of
Scala notebook centered on Spark development, with integrated spark SQL support. Spark notebook
allows you to use JavaScript directly to create visualizations.
One last notebook solution is databricks cloud. It’s currently only available on Amazon
Web Services and runs on your EC2 account. Here we see parts of the Zeppelin interface.
You use special tags to identify which backend to use. The default (no tags) is Scala. A
SparkContext is automatically instantiated with the variable “sc”. There is also
an SQLContextThe sql, sh, and md tags specify SQL, bash shell, and markdown, respectively.
The play button, or shift-enter for short, executes the panel. You can toggle the output
display and change the panel settings as well. You will become familiar with Zeppelin in
the lab exercises. Having completed this lesson you should be
able to use Zeppelin in your Spark projects and identify the various notebooks you can
use with Spark. Procees to exercise 1 and the next lesson.